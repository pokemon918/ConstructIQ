# ConstructIQ - Semantic API Prototype

A FastAPI-based semantic search API for construction permit data from the City of Austin.

## ğŸ¯ Project Overview

This project implements a semantic search system for construction permit data that:
- Normalizes raw permit records into a clean schema
- Embeds permit data using OpenAI's text-embedding-3-small
- Indexes data in a vector database for semantic search
- Exposes a RESTful API with filtering and query logging capabilities

## ğŸ—ï¸ Project Structure

```
ConstructIQ/
â”œâ”€â”€ app/                    # Main application code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py            # FastAPI application entry point
â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â”œâ”€â”€ models/            # Data models and schemas
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ permit.py      # Permit data models
â”‚   â”‚   â””â”€â”€ api.py         # API request/response models
â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embedding.py   # OpenAI embedding service
â”‚   â”‚   â”œâ”€â”€ vector_db.py   # Vector database operations
â”‚   â”‚   â””â”€â”€ permit.py      # Permit data processing
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ search.py      # Search endpoint
â”‚   â”‚   â””â”€â”€ health.py      # Health check endpoint
â”‚   â””â”€â”€ utils/             # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py      # Logging configuration
â”‚       â””â”€â”€ data_processor.py # Data normalization utilities
â”œâ”€â”€ data/                  # Data files
â”‚   â”œâ”€â”€ raw/              # Raw permit data
â”‚   â””â”€â”€ processed/        # Normalized permit data
â”œâ”€â”€ tests/                # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_services.py
â”‚   â””â”€â”€ test_utils.py
â”œâ”€â”€ scripts/              # Utility scripts
â”‚   â”œâ”€â”€ load_data.py      # Data loading script
â”‚   â”œâ”€â”€ process_data.py   # Data processing script
â”‚   â”œâ”€â”€ create_embeddings.py # Embedding and indexing pipeline
â”‚   â””â”€â”€ example_usage.py  # Example usage demonstration
â”œâ”€â”€ docs/                 # Documentation
â”‚   â””â”€â”€ api.md           # API documentation
â”œâ”€â”€ .env.example         # Environment variables template
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ Dockerfile          # Container configuration
â”œâ”€â”€ docker-compose.yml  # Local development setup
â””â”€â”€ README.md           # This file
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- OpenAI API key
- Pinecone API key and environment

### Installation

1. **Clone and setup environment:**
```bash
git clone <repository-url>
cd ConstructIQ
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

2. **Configure environment:**
```bash
cp .env.example .env
# Edit .env with your API keys and configuration
```

3. **Load and process data:**
```bash
# Load raw data from Austin API
python scripts/load_data.py

# Process and normalize data
python scripts/process_data.py

# Create embeddings and index in Pinecone
python scripts/create_embeddings.py
```

4. **Run the application:**
```bash
uvicorn app.main:app --reload
```

5. **Access the API:**
- API Documentation: http://localhost:8000/docs
- Health Check: http://localhost:8000/healthz
- Search Endpoint: POST http://localhost:8000/search

## ğŸ“Š Data Schema

The normalized permit schema groups fields logically:

```json
{
  "metadata": {
    "record_id": "string",
    "validation_status": "string"
  },
  "permit_info": {
    "permit_number": "string",
    "permit_type": "string",
    "permit_type_description": "string",
    "permit_class": "string",
    "work_class": "string",
    "status": "string",
    "description": "string"
  },
  "location": {
    "address": "string",
    "city": "string",
    "state": "string",
    "zip_code": "string",
    "latitude": "float",
    "longitude": "float",
    "council_district": "string"
  },
  "dates": {
    "applied_date": "string",
    "issue_date": "string",
    "calendar_year": "string",
    "expires_date": "string"
  },
  "project": {
    "project_id": "string",
    "master_permit_number": "string"
  },
  "valuation": {
    "total_job_valuation": "float",
    "total_new_addition_sqft": "float",
    "total_existing_building_sqft": "float"
  },
  "contractor": {
    "contractor_company_name": "string",
    "contractor_trade": "string",
    "contractor_full_name": "string"
  },
  "applicant": {
    "applicant_full_name": "string",
    "applicant_organization": "string"
  }
}
```

## ğŸ” Embedding and Vector Search

The system uses OpenAI's `text-embedding-3-small` model to create semantic embeddings from permit records. Text blocks are constructed from relevant fields:

- **Description**: Permit description and work details
- **Permit Type**: Type and classification information
- **Work Class**: Specific work category
- **Location**: Address and geographic information
- **Contractor**: Contractor company and trade information
- **Applicant**: Applicant name and organization
- **Valuation**: Project value and square footage

### Search Capabilities

- **Semantic Search**: Find permits by natural language queries
- **Filtered Search**: Combine semantic search with metadata filters
- **Vector Similarity**: Direct vector similarity search
- **Metadata Filtering**: Filter by permit type, location, dates, valuation, etc.

## ğŸ” API Endpoints

### POST /search
Semantic search for permits with filtering capabilities.

**Request:**
```json
{
  "query": "commercial remodel downtown",
  "filters": {
    "permit_type": "Commercial",
    "calendar_year_issued": 2023
  }
}
```

**Response:**
```json
{
  "results": [
    {
      "permit_id": "string",
      "similarity_score": 0.95,
      "permit_data": { ... }
    }
  ],
  "total_results": 5,
  "query_time_ms": 150
}
```

### GET /healthz
Health check endpoint.

### GET /docs
Interactive API documentation (Swagger UI).

## ğŸ› ï¸ Development

### Running the Embedding Pipeline

1. **Load raw data:**
```bash
python scripts/load_data.py
```

2. **Process and normalize data:**
```bash
python scripts/process_data.py
```

3. **Create embeddings and index:**
```bash
python scripts/create_embeddings.py --raw-data data/raw/austin_permits.json --index-name austin-permits-v1
```

4. **Test search functionality:**
```bash
python scripts/example_usage.py
```

### Running Tests
```bash
pytest tests/
```

### Code Formatting
```bash
black app/ tests/
isort app/ tests/
```

### Type Checking
```bash
mypy app/
```

## ğŸš€ Deployment

### Docker Deployment
```bash
docker build -t constructiq-api .
docker run -p 8000:8000 constructiq-api
```

### Environment Variables
- `OPENAI_API_KEY`: Your OpenAI API key
- `PINECONE_API_KEY`: Your Pinecone API key
- `PINECONE_ENVIRONMENT`: Your Pinecone environment (e.g., "us-east-1-aws")
- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR)

## ğŸ“ Logging

The application logs:
- Search queries with timestamps
- Applied filters
- Top result IDs
- Performance metrics

Logs are written to both console and file for analytics support.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is part of the ConstructIQ technical challenge.
